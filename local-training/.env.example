# Local Training Environment Variables

# Model Configuration
BASE_MODEL_NAME=microsoft/DialoGPT-medium
MODEL_PATH=./models/medgemma-local-v1

# AWS Configuration
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AWS_DEFAULT_REGION=us-east-1
AWS_PROFILE=default

# S3 Buckets
S3_TRAINING_BUCKET=harness-training-data-development
S3_MODEL_BUCKET=harness-model-artifacts-development
S3_CORPUS_BUCKET=harness-veterinary-corpus-development
S3_EMBEDDINGS_BUCKET=harness-embeddings-development

# Training Configuration
MAX_LENGTH=512
TRAIN_BATCH_SIZE=1
GRADIENT_ACCUMULATION_STEPS=32
LEARNING_RATE=2e-5
NUM_EPOCHS=3

# LoRA Configuration
LORA_R=16
LORA_ALPHA=32
LORA_DROPOUT=0.1

# Inference Server
INFERENCE_HOST=0.0.0.0
INFERENCE_PORT=8000

# Data Pipeline APIs
NCBI_API_KEY=38567ebe3d4d79241ae2dfd7e75d6d89e209
CROSSREF_EMAIL=admin@harness.health

# Experiment Tracking (Optional)
WANDB_API_KEY=
WANDB_PROJECT=harness-local-training
MLFLOW_TRACKING_URI=

# Mac Mini Optimizations
PYTORCH_ENABLE_MPS_FALLBACK=1
TOKENIZERS_PARALLELISM=false

# Development
ENVIRONMENT=development
LOG_LEVEL=INFO